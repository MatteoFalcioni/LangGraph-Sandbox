Metadata-Version: 2.4
Name: langgraph-sandbox
Version: 0.1.0
Summary: A sandbox environment for LangGraph with artifact storage and dataset management
Author: Matteo Falcioni
License: MIT
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: langgraph==0.6.7
Requires-Dist: langgraph-checkpoint==2.1.0
Requires-Dist: langchain-core==0.3.75
Requires-Dist: langchain-community==0.3.29
Requires-Dist: langchain-openai==0.3.32
Requires-Dist: openai==1.106.1
Requires-Dist: pydantic==2.11.7
Requires-Dist: typing_extensions>=4.10
Requires-Dist: python-dotenv==1.1.1
Requires-Dist: docker==7.1.0
Requires-Dist: fastapi==0.116.1
Requires-Dist: uvicorn==0.35.0
Requires-Dist: orjson==3.10.18
Requires-Dist: httpx
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: requires-python

# LangGraph Sandbox – Docker-Based Code Execution Environment

A production-ready Docker sandbox for executing Python code within LangGraph agentic systems. Provides secure, isolated code execution with persistent state, dataset management, and automatic artifact storage.

## Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Execution Modes](#execution-modes)
- [Quick Start](#quick-start)
- [Configuration](#configuration)
- [Usage Examples](#usage-examples)
- [Artifact System](#artifact-system)
- [Session Management](#session-management)
- [Development & Debugging](#development--debugging)
- [Installation](#installation)
- [API Reference](#api-reference)
- [Security](#security)
- [Troubleshooting](#troubleshooting)

## Overview

This sandbox replaces services like E2B by running isolated Docker containers for each conversation session. It provides:

- **Session-pinned containers**: One container per conversation with persistent Python state
- **Multiple storage modes**: RAM (TMPFS) or disk (BIND) for session data
- **Flexible dataset access**: No datasets, local read-only mounts, or API-based staging
- **Automatic artifact management**: Files are deduplicated, stored securely, and accessible via signed URLs
- **Enhanced debugging**: Complete execution logs and state inspection in BIND mode

## Key Features

- ✅ **Resource isolation**: CPU, memory, and timeout limits
- ✅ **Session state persistence**: Variables and imports persist across tool calls
- ✅ **Six execution modes**: From simple code execution to full dataset analysis
- ✅ **Automatic artifact pipeline**: Deduplication, metadata tracking, and secure downloads
- ✅ **Enhanced debugging**: Complete execution logs and state snapshots (BIND mode)
- ✅ **Production-ready**: Secure token system, configurable timeouts, and error handling

## Execution Modes

The system offers six execution modes based on two independent configuration knobs:

| Mode | Session Storage | Dataset Access | Description | Best For |
|------|----------------|----------------|-------------|----------|
| **TMPFS_NONE** | RAM (TMPFS) | None | Simple sandbox in memory | Algorithms, calculations, demos |
| **BIND_NONE** | Disk (BIND) | None | Persistent sandbox on disk | Debugging, persistent development |
| **TMPFS_LOCAL** | RAM (TMPFS) | Local RO | Memory + host datasets | Fast analysis with large datasets |
| **BIND_LOCAL** | Disk (BIND) | Local RO | Persistent + host datasets | Full development with datasets |
| **TMPFS_API** | RAM (TMPFS) | API | Memory + API datasets | Multi-tenant, cloud datasets |
| **BIND_API** | Disk (BIND) | API | Persistent + API datasets | Development with API datasets |

### Recommended Defaults

- **Simple coding**: `TMPFS_NONE` - Perfect for general-purpose coding without datasets
- **Production demos**: `TMPFS_API` - Multi-tenant with dynamic dataset loading
- **Local development**: `BIND_LOCAL` - Full debugging with local datasets

## Quick Start

### Option 1: Python Package Installation (Recommended)

```bash
# Clone and install the package
git clone https://github.com/MatteoFalcioni/LangGraph-Sandbox
cd LangGraph-Sandbox
pip install -e .

# Build the Docker image
docker build -t sandbox:latest -f Dockerfile .
```

Set your OpenAI API key by modifying the `example.env` file, or set environment variable:

```bash
export OPENAI_API_KEY=your_api_key_here
```

And then you can run a simple example

```bash
# Run the simple sandbox
langgraph-sandbox
```

### Option 2: Manual Installation

```bash
# Clone the repository and build the Docker Image
git clone https://github.com/MatteoFalcioni/LangGraph-Sandbox
cd LangGraph-Sandbox
docker build -t sandbox:latest -f Dockerfile .

# Install Dependencies
pip install -r requirements.txt
```

Then set your OpenAI API key by modifying the `example.env` file, or set environment variable:

Create a `.env` file or set environment variable:
```bash
export OPENAI_API_KEY=your_api_key_here
```

And then you can run a simple example:

```bash
# Run Simple Example
DATASET_ACCESS=NONE python main.py
```

## Configuration

Configuration is managed through environment variables with sensible defaults:

### Core Settings

```env
# Session storage: TMPFS (RAM) or BIND (disk)
SESSION_STORAGE=TMPFS

# Dataset access: NONE, LOCAL_RO, or API
DATASET_ACCESS=API

# Paths (optional - defaults provided)
SESSIONS_ROOT=./sessions
BLOBSTORE_DIR=./blobstore
ARTIFACTS_DB=./artifacts.db

# Required only for LOCAL_RO mode
DATASETS_HOST_RO=./example_llm_data

# Docker settings
SANDBOX_IMAGE=sandbox:latest
TMPFS_SIZE_MB=1024
```

### Quick Configuration Examples

**Simple execution:**
```bash
DATASET_ACCESS=NONE python main.py
```

**Local development:**
```bash
SESSION_STORAGE=BIND DATASET_ACCESS=LOCAL_RO DATASETS_HOST_RO=./data python main.py
```

**Production (default):**
```bash
python main.py
```

## Usage Examples

The repository includes three complete examples demonstrating different modes:

### Simple Sandbox (TMPFS_NONE)
```bash
cd usage_examples/simple_sandbox
python main.py
```
- No datasets, pure code execution
- Perfect for algorithms and calculations
- Everything runs in memory

### Fully Local (BIND_LOCAL)
```bash
cd usage_examples/fully_local
python main.py
```
- Persistent session storage
- Local datasets mounted read-only
- Full debugging capabilities

### TMPFS API (TMPFS_API)
```bash
cd usage_examples/tmpfs_api
python main.py
```
- Dynamic dataset fetching via API
- Memory-based caching
- Multi-tenant ready

## Artifact System

Files saved to `/session/artifacts/` are automatically processed:

1. **Ingestion**: Files are copied from the container
2. **Deduplication**: SHA-256 based content addressing
3. **Storage**: Saved in `blobstore/` with metadata in SQLite
4. **Access**: Secure download URLs with time-limited tokens
5. **Cleanup**: Original files removed from session directory

### Artifact Features

- **Automatic deduplication**: Identical files share storage
- **Secure downloads**: Signed URLs with configurable expiration
- **Metadata tracking**: Size, MIME type, creation time, session links
- **Content addressing**: SHA-256 based blob storage
- **API access**: REST endpoints for artifact management

### Security

- ✅ **Auto-generated secrets**: Secure token signing keys
- ✅ **Short-lived tokens**: Default 10-minute expiration
- ✅ **No manual configuration**: Works out of the box
- ✅ **Content verification**: SHA-256 integrity checking

## Session Management

### Session Lifecycle

1. **Creation**: Container started with session-specific configuration
2. **Execution**: Code runs with persistent Python state
3. **Artifact Processing**: Files automatically ingested after each run
4. **Cleanup**: Container stopped, resources released

### Session State

- **Variables**: All Python variables persist between executions
- **Imports**: Module imports remain available
- **Working Directory**: Consistent `/session` working directory
- **Environment**: Isolated Python environment with common packages

## Development & Debugging

### BIND Mode Enhanced Features

When using `SESSION_STORAGE=BIND`, the system provides comprehensive debugging capabilities:

#### Session Directory Structure
```
sessions/<session_id>/
├── session.log                    # Complete execution history
├── session_metadata.json          # Session info and statistics
├── python_state.json             # Current Python state snapshot
└── artifacts/                    # Files before ingestion
```

#### Session Viewer Tool
```bash
# View complete session information
python src/sandbox/session_viewer.py sessions/<session_id>

# View last 10 log entries
python src/sandbox/session_viewer.py sessions/<session_id> --limit 10

# Skip state and artifacts display
python src/sandbox/session_viewer.py sessions/<session_id> --no-state --no-artifacts
```

#### Debugging Benefits

- **Complete execution history**: See all code executed and results
- **State inspection**: View variables, imports, and Python environment
- **Artifact tracking**: Monitor file creation and processing
- **Container information**: Track container lifecycle and configuration
- **Performance analysis**: Execution timing and resource usage

### Available Tools

The system provides two main tools:

1. **`code_sandbox`**: Execute Python code with persistent state
2. **`export_datasets`**: Export modified datasets to host filesystem


### Docker Image

The sandbox runs in a custom Docker image with:
- Python 3.11
- Common data science packages (pandas, numpy, matplotlib, etc.)
- Security-hardened configuration
- Resource limits and timeouts

## API Reference

### Artifact API Endpoints

- `GET /artifacts/{artifact_id}?token={token}` - Download artifact
- `HEAD /artifacts/{artifact_id}?token={token}` - Get artifact metadata

### Configuration API

- `Config.from_env()` - Load configuration from environment
- `Config.from_env(env_file_path)` - Load from specific file

### Session Management

- `SessionManager.start(session_id)` - Start new session
- `SessionManager.exec(session_id, code)` - Execute code
- `SessionManager.stop(session_id)` - Stop session
## Troubleshooting

### Common Issues

**Container startup failures:**
- Ensure Docker is running
- Check `SANDBOX_IMAGE` points to correct image
- Verify sufficient disk space

**Dataset access problems:**
- For `LOCAL_RO`: Ensure `DATASETS_HOST_RO` path exists
- For `API`: Check network connectivity and API configuration
- Verify dataset files are in Parquet format

**Artifact download failures:**
- Check artifact server is running (port 8000)
- Verify token hasn't expired
- Ensure artifact ID is correct

## Next Steps

- **Quotas**: Add per-session size limits and retention policies
- **Scalability**: Migrate to Postgres + S3/MinIO for production
- **Monitoring**: Add metrics and health checks
- **Extensions**: Support for additional languages and frameworks

For more examples and detailed documentation, see the `usage_examples/` directory.
